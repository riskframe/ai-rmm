[//]: # (COPYRIGHT)
[//]: # (RiskFrame.ai - AI Risk Management and Resilience Framework)
[//]: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm)
[//]: # (SOFTWARE LICENSE)
[//]: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
    
## Measure 2.7: AI system security and resilience – as identified in the map function – are evaluated and documented.

### Measure 2.7.1. Establish a Security and Resilience Evaluation Framework.

#### Sub Practices

1. Define a comprehensive framework for evaluating the security and resilience of the AI system, encompassing the identification, assessment, and mitigation of potential security threats and vulnerabilities.

2. Identify and categorize security risks based on their severity, likelihood, and potential impact on the AI system, its data, and its users.

3. Establish clear criteria for determining whether residual security risks are acceptable or require further mitigation.

### Measure 2.7.2. Develop Security and Resilience Metrics and Thresholds.

#### Sub Practices

1. Establish quantitative and qualitative security metrics to assess the AI system's ability to withstand cyberattacks and maintain its functionality.

2. Metrics should reflect the system's ability to protect its data and code from unauthorized access or modification, its ability to detect and respond to malicious activity, and its overall resilience to disruptions.

3. Define thresholds for each security metric to determine whether the AI system meets the organization's security standards and risk tolerance.

### Measure 2.7.3. Conduct Regular Security and Resilience Assessments.

#### Sub Practices

1. Conduct regular security and resilience assessments throughout the AI system's lifecycle, including during development, testing, and deployment phases.

2. Identify new or emerging security threats and vulnerabilities as the AI system evolves and its environment changes.

3. Assess the effectiveness of security measures and adjust protection strategies as needed.

### Measure 2.7.4. Prioritize Security and Resilience Enhancement.

#### Sub Practices

1. Prioritize security and resilience enhancements based on their potential impact on the AI system's security posture and the organization's risk tolerance.

2. Develop and implement appropriate security and resilience enhancement measures, such as incorporating security best practices, implementing access control mechanisms, and utilizing vulnerability scanning tools.

3. Evaluate the effectiveness of security enhancement measures and make necessary adjustments.

### Measure 2.7.5. Implement Multilayered Defense Strategies.

#### Sub Practices

1. Adopt a layered defense approach to security, utilizing multiple security controls and techniques to create a robust defense against cyberattacks.

2. Employ a combination of physical, logical, and procedural security controls to protect the AI system, its data, and its infrastructure.

3. Regularly review and update security controls to address evolving threats and vulnerabilities.

### Measure 2.7.6. Conduct Regular Penetration Testing and Red Team Exercises.

#### Sub Practices

1. Engage external security experts to conduct penetration testing and red team exercises to identify and assess potential vulnerabilities in the AI system and its security controls.

2. Utilize penetration testing and red team exercises to simulate real-world cyberattack scenarios and evaluate the system's ability to defend against them.

3. Use the findings from penetration testing and red team exercises to refine security measures and improve the AI system's overall resilience.

### Measure 2.7.7. Implement Regular Security Patching and Updates.

#### Sub Practices

1. Establish a process for timely patching and updating the AI system's software, libraries, and operating system to address identified vulnerabilities.

2. Implement automated patching mechanisms to ensure that security updates are applied promptly and consistently across the AI system's infrastructure.

3. Maintain a comprehensive record of security patches and updates to track remediation efforts and ensure consistent compliance.

### Measure 2.7.8. Document Security and Resilience Evaluation and Enhancement.

#### Sub Practices

1. Maintain a comprehensive record of security and resilience evaluations, mitigation strategies, and test results.

2. Document the rationale behind risk prioritization, enhancement choices, and security decision-making processes.

3. Share security risk documentation with relevant stakeholders, including developers, operators, and risk managers.

### Measure 2.7.9. Continuously Evaluate and Enhance Security and Resilience.

#### Sub Practices

1. Regularly evaluate the effectiveness of the AI system's security and resilience practices, identifying areas for improvement and adapting strategies as the system evolves.

2. Gather feedback from stakeholders, including developers, operators, and users, to refine security assessment and enhancement approaches.

3. Stay informed about emerging security threats, vulnerabilities, and technological advancements in cybersecurity to maintain the AI system's security posture.

