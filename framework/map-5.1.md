[//]: # (COPYRIGHT)
[//]: # (RiskFrame.ai - AI Risk Management and Resilience Framework)
[//]: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm)
[//]: # (SOFTWARE LICENSE)
[//]: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
    
# Map 5: Impacts to individuals, groups, communities, organizations, and society are characterized.

## Map 5.1: Likelihood and magnitude of each identified impact (both potentially beneficial and harmful) based on expected use, past uses of AI systems in similar contexts, public incident reports, feedback from those external to the team that developed or deployed the AI system, or other data are identified and documented.

### Map 5.1.1. Identify Potential Impacts.

From a methodology perspective, identifying potential impacts involves a systematic approach that considers various sources of information and data. This includes analyzing expected use cases, past experiences with similar AI systems in comparable contexts, public incident reports, and feedback from external stakeholders not directly involved in the AI system's development or deployment. By synthesizing insights from these sources, teams can gain a comprehensive understanding of the likelihood and magnitude of both beneficial and harmful impacts associated with the AI system.

Utilizing a systematic approach, assessing potential impacts involves thoroughly evaluating the AI system's effects, encompassing various stakeholders and scenarios. This includes scrutinizing impacts across diverse dimensions such as social, economic, environmental, and ethical realms. By documenting these impacts systematically, teams ensure clarity and structured categorization, facilitating a comprehensive understanding of both positive and negative consequences associated with the AI system.

#### Sub Practices

1. Thoroughly evaluate the potential impacts of the AI system, both beneficial and harmful, considering all stakeholders and potential use cases.

2. Assess potential impacts across a range of dimensions, including social, economic, environmental, and ethical considerations.

3. Document the identified impacts in a clear and structured format, ensuring they are clearly categorized and distinguished.

### Map 5.1.2. Assess Likelihood and Magnitude.

Utilizing various sources of information and data, assessing the likelihood and magnitude of identified impacts involves a comprehensive evaluation process. This includes analyzing historical data from past uses of AI systems in similar contexts, studying public incident reports, and gathering feedback from external stakeholders not directly involved in the AI system's development or deployment. By synthesizing insights from these diverse sources, teams can determine the probability and scale of both beneficial and harmful impacts associated with the AI system, enabling informed decision-making and risk management strategies.

Incorporating various sources of information and data, assessing the likelihood and magnitude of identified impacts involves systematically evaluating each impact. This includes analyzing factors such as the AI system's design, deployment context, and potential misuse scenarios to determine the likelihood of occurrence. Additionally, assessing the magnitude of impacts involves evaluating their severity and potential consequences for individuals, organizations, and society. Employing suitable methods and tools, such as risk assessment frameworks or impact modeling techniques, enables teams to quantify these aspects effectively, facilitating informed decision-making and risk management strategies.

#### Sub Practices

1. For each identified impact, assess the likelihood of its occurrence, considering factors such as the design of the AI system, the context of its deployment, and potential misuse scenarios.

2. Assess the magnitude of each impact, evaluating its potential severity and potential impact on individuals, organizations, and society.

3. Use appropriate methods and tools to quantify the likelihood and magnitude of impacts, such as risk assessment frameworks or impact modeling techniques.

### Map 5.1.3. Consider Past Experiences and External Feedback.

Drawing on past experiences and external feedback is integral to comprehensively characterizing the likelihood and magnitude of identified impacts associated with AI systems. By examining past uses of AI systems in similar contexts and analyzing public incident reports, teams can glean valuable insights into potential risks and benefits. Moreover, gathering feedback from stakeholders external to the development or deployment process offers diverse perspectives, enriching the understanding of potential impacts. Integrating these sources of information enables teams to enhance the accuracy and robustness of their impact assessments, contributing to informed decision-making and effective risk management strategies.

By analyzing past uses of AI systems, reviewing public incident reports, and gathering stakeholder feedback, teams enhance their understanding of potential impacts. This involves examining historical deployments to identify risks and opportunities, studying incident reports for insights into challenges, and soliciting diverse perspectives from stakeholders. Integrating these practices enriches impact assessments, facilitating informed decision-making and robust risk management strategies.

#### Sub Practices

1. Analyze past uses of AI systems in similar contexts to identify potential risks and opportunities associated with the AI system's deployment.

2. Review public incident reports and research findings related to AI systems to gain insights into potential challenges and unintended consequences.

3. Gather feedback from stakeholders, including experts, users, and potential beneficiaries, to understand their perspectives and concerns about the AI system's impacts.

### Map 5.1.4. Document Impact Likelihood and Magnitude.

Utilizing various sources of information and data, documenting impact likelihood and magnitude involves systematically recording the probability and scale of identified impacts associated with the AI system. This includes categorizing impacts as beneficial or harmful and assigning a likelihood score based on factors such as historical data, expert assessments, and stakeholder feedback. Similarly, the magnitude of each impact is assessed, considering its potential severity and scope across different dimensions. By documenting these assessments in a structured format, teams create a comprehensive record of the potential consequences of AI system deployment, enabling informed decision-making and risk mitigation strategies.

Documenting impact likelihood and magnitude involves creating comprehensive documentation that outlines the identified impacts, their likelihood, magnitude, and the rationale behind the assessment. Presenting the impact assessment findings in a structured and easy-to-understand format, using visualizations or tables to illustrate key findings, enhances clarity. Ensuring accessibility of this documentation to relevant stakeholders facilitates informed decision-making about AI system development and deployment, promoting effective risk management strategies.

#### Sub Practices

1. Create comprehensive documentation that outlines the identified impacts, their likelihood, their magnitude, and the rationale behind the assessment.

2. Present the impact assessment findings in a structured and easy-to-understand format, using visualizations or tables to illustrate the key findings.

3. Ensure that the documentation is accessible to relevant stakeholders and facilitates informed decision-making about the AI system's development and deployment.

### Map 5.1.5. Continuously Monitor and Update Impact Assessment.

Continuously monitoring and updating impact assessment involves regularly reviewing and updating the assessment as the AI system evolves, its use cases expand, and new information becomes available. This entails incorporating feedback from users, stakeholders, and researchers to refine the assessment and identify emerging risks or opportunities. By maintaining a living document that reflects the dynamic nature of the AI system's impacts, teams ensure ongoing alignment with evolving technological and societal landscapes, facilitating responsible AI development and decision-making.

This practice involves regularly reviewing and updating the assessment as the AI system evolves, its use cases expand, and new information becomes available. This entails incorporating feedback from users, stakeholders, and researchers to refine the assessment and identify emerging risks or opportunities. By maintaining a living document that reflects the dynamic nature of the AI system's impacts, teams ensure ongoing alignment with evolving technological and societal landscapes, facilitating responsible AI development and decision-making.

#### Sub Practices

1. Regularly review and update the impact assessment as the AI system evolves, its use cases expand, and new information becomes available.

2. Incorporate feedback from users, stakeholders, and researchers to refine the assessment and identify emerging risks or opportunities.

3. Maintain a living document that reflects the dynamic nature of the AI system's impacts and serves as an ongoing resource for responsible AI development.

