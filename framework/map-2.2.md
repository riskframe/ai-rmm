[//]: # (COPYRIGHT)
[//]: # (RiskFrame.ai - AI Risk Management and Resilience Framework)
[//]: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm)
[//]: # (SOFTWARE LICENSE)
[//]: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
    
## Map 2.2
> Information about the AI systemâ€™s knowledge limits and how system output may be utilized and overseen by humans is documented. Documentation provides sufficient information to assist relevant AI actors when making decisions and taking subsequent actions. [@playbook]

### Map 2.2.1. Identify and Document AI System Knowledge Limits.

Identify and document the knowledge limits of the AI system entails recognizing the boundaries of its understanding and capabilities. This involves determining the specific areas or scenarios where the AI system may lack proficiency or encounter challenges in providing accurate or reliable outputs. By clearly delineating these knowledge limits, stakeholders gain insight into the system's constraints and can make informed decisions about its appropriate use and oversight.

Identifying and documenting AI system knowledge limits involves analyzing its understanding and processing capabilities, recognizing biases and data limitations, and specifying situations requiring human intervention.

#### Sub Practices

1. Conduct a comprehensive analysis of the AI system's knowledge base and its ability to understand, process, and generate information.

2. Identify potential sources of bias, data limitations, and areas where the AI system may lack expertise.

3. Document the system's knowledge limits in a clear and concise manner, specifying the types of situations where the AI system may need human intervention or guidance.

### Map 2.2.2. Define Human Oversight and Overriding Mechanisms.

Defining human oversight and overriding mechanisms involves establishing protocols and procedures for human involvement in monitoring and controlling AI system outputs. This includes defining the roles and responsibilities of human overseers, specifying criteria for intervention, and implementing mechanisms for human intervention when necessary to ensure the reliability, safety, and ethical use of the AI system.

Establishing clear procedures for human oversight and intervention involves defining roles and responsibilities for human operators, outlining the criteria for intervention, and implementing mechanisms for overriding or correcting AI decisions when necessary.

#### Sub Practices

1. Establish clear procedures for human oversight and intervention in the AI system's operation.

2. Define roles and responsibilities for human operators who will monitor, interpret, and approve AI-generated outputs.

3. Implement mechanisms for human operators to override or correct AI decisions when necessary.

### Map 2.2.3. Document Human Oversight and Overriding Procedures.

To ensure transparency and accountability in AI systems, it is essential to document human oversight and overriding procedures comprehensively. This documentation should outline the specific steps and protocols for human operators to monitor AI system outputs, intervene when necessary, and override automated decisions. It should also clarify the criteria for human intervention, the escalation process for challenging cases, and the mechanisms for documenting and reviewing human actions. By documenting these procedures, relevant AI actors can better understand their roles and responsibilities in overseeing AI system outputs and taking appropriate actions when needed.

Documenting human oversight and overriding procedures involves creating comprehensive documentation that outlines the roles and responsibilities of human operators, detailing their training requirements and decision-making processes, and explaining the triggers for human intervention and how overriding actions will be initiated and documented.

#### Sub Practices

1. Create comprehensive documentation that outlines the specific human oversight and overriding procedures for the AI system.

2. Detail the roles and responsibilities of human operators, including their training requirements and decision-making processes.

3. Explain the triggers for human intervention and how overriding actions will be initiated and documented.

### Map 2.2.4. Integrate Human Oversight and Overriding into System Architecture.

Integrating human oversight and overriding into the system architecture involves designing the AI system in a way that seamlessly incorporates mechanisms for human intervention and control. This includes developing interfaces and functionalities that allow human operators to monitor system outputs, intervene when necessary, and override automated decisions. Additionally, the system architecture should facilitate real-time communication between the AI system and human operators, enabling efficient collaboration and decision-making.

Designing the AI system's architecture to facilitate human oversight and overriding capabilities involves integrating interfaces and functionalities that enable human operators to monitor system outputs and intervene as needed. Developing interfaces for human operators to interact with the AI system, receive alerts, and initiate intervention processes is essential for effective oversight. Additionally, implementing mechanisms for logging and tracking human oversight and overriding activities ensures accountability and facilitates auditing processes.

#### Sub Practices

1. Design the AI system's architecture to facilitate human oversight and overriding capabilities.

2. Develop interfaces for human operators to interact with the AI system, receive alerts, and initiate intervention processes.

3. Implement mechanisms for logging and tracking human oversight and overriding activities for auditing and accountability purposes.

### Map 2.2.5. Continuously Assess and Update Knowledge Limits Documentation.

Continuously assessing and updating knowledge limits documentation involves regularly reviewing and revising the documented information about the AI system's knowledge boundaries and the roles of human oversight. This process ensures that the documentation remains accurate and reflective of the AI system's evolving capabilities and limitations. By staying vigilant and proactive in updating this documentation, organizations can provide relevant AI actors with up-to-date information to support their decision-making processes and ensure effective oversight of AI system outputs.

This process on the AI system's knowledge limits involves regularly revising the documentation as the system evolves and new data is incorporated, integrating feedback from human operators and stakeholders to refine understanding, and maintaining a living document that reflects the current knowledge of the AI system's capabilities and the role of human oversight in ensuring responsible decision-making.

#### Sub Practices

1. Regularly review and update documentation on the AI system's knowledge limits as the system evolves and new data is incorporated.

2. Incorporate feedback from human operators and stakeholders to refine understanding of the system's capabilities and limitations.

3. Maintain a living document that reflects the current knowledge of the AI system's capabilities and the role of human oversight in ensuring responsible decision-making.

### Map 2.2 Suggested Work Products

* Knowledge Limits Analysis Report - Document detailing the AI system's understanding, processing capabilities, and identified knowledge limits, including potential sources of bias and data limitations.
* Overriding Mechanism Manual - Detailed instructions and protocols for human operators on how to override or correct AI decisions, including the criteria for intervention and the steps to take when intervention is necessary.
* System Architecture Design Document - A technical document that describes how the AI system's architecture integrates human oversight and overriding functionalities, including interface designs and communication protocols.
* Training Material for Human Operators - Educational content and training modules designed to equip human operators with the knowledge and skills required to effectively monitor, interpret, and intervene in the AI system's operations.
* Human-AI Interaction Logs - Structured records capturing all instances of human intervention, including the rationale for overriding AI decisions, to ensure accountability and facilitate auditing processes.
* Continuous Improvement Plan - A strategic plan outlining the processes for regularly reviewing and updating the AI system's knowledge limits documentation, incorporating feedback from stakeholders and adapting to new insights.
* Incident Response Plan - A detailed plan that specifies the steps to be taken by human operators in response to identified issues or anomalies in the AI system's performance, including escalation procedures for complex cases.
* Human Oversight Feedback Loop Report - Periodic reports summarizing feedback from human operators on the AI system's performance, highlighting areas for improvement in both the AI system and the oversight mechanisms.
* AI System Evolution Tracker - A dynamic document or digital tool designed to track changes and updates in the AI system's capabilities and knowledge limits over time, ensuring that all stakeholders have access to the most current information.
