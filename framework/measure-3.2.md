[//]: # (COPYRIGHT)
[//]: # (RiskFrame.ai - AI Risk Management and Resilience Framework)
[//]: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm)
[//]: # (SOFTWARE LICENSE)
[//]: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
    
## Measure 3.2: Risk tracking approaches are considered for settings where AI risks are difficult to assess using currently available measurement techniques or where metrics are not yet available.

### Measure 3.2.1. Recognize Risk Measurement Limitations.

#### Sub Practices

1. Acknowledge that existing AI risk assessment methodologies and metrics may not fully capture the complexity and dynamic nature of AI systems.

2. Recognize that some AI risks may be difficult or impossible to quantify using traditional risk assessment techniques.

3. Understand that the absence of established metrics does not imply the absence of risk and should not hinder risk identification and mitigation efforts.

### Measure 3.2.2. Employ Alternative Risk Assessment Methods.

#### Sub Practices

1. Utilize alternative risk assessment approaches, such as qualitative risk assessment, scenario analysis, and expert judgment, to assess risks that are difficult to quantify.

2. Conduct structured workshops and discussions with AI experts, domain experts, and stakeholders to identify potential risks and their potential impacts.

3. Employ data visualization techniques, such as dashboards and charts, to present risk information in a clear and understandable manner, even without numerical metrics.

### Measure 3.2.3. Leverage Emerging Risk Assessment Tools.

#### Sub Practices

1. Explore and adopt emerging risk assessment tools and methodologies specifically designed for AI systems.

2. Consider tools that incorporate machine learning techniques to analyze large datasets and identify patterns that may indicate potential risks.

3. Evaluate the effectiveness of these tools in assessing risks that are not readily captured by traditional methods.

### Measure 3.2.4. Collaborate with Research and Standards Bodies.

#### Sub Practices

1. Engage with research communities and standards organizations to contribute to the development of new risk assessment metrics and methodologies for AI systems.

2. Participate in research projects and initiatives that aim to address the limitations of existing risk assessment techniques for AI.

3. Advocate for the development of standardized risk assessment frameworks and metrics that can be widely adopted across the AI industry.

### Measure 3.2.5. Promote Risk Awareness and Education.

#### Sub Practices

1. Foster a culture of risk awareness and responsibility among AI developers, operators, and decision-makers.

2. Educate stakeholders on the unique challenges of risk assessment in AI systems and the importance of considering alternative approaches when traditional methods are not feasible.

3. Integrate risk management considerations into organizational training programs and educational materials.

