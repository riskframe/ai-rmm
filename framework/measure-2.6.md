[//]: # (COPYRIGHT)
[//]: # (RiskFrame.ai - AI Risk Management and Resilience Framework)
[//]: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm)
[//]: # (SOFTWARE LICENSE)
[//]: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
    
## Measure 2.6: The AI system is evaluated regularly for safety risks â€“ as identified in the map function. The AI system to be deployed is demonstrated to be safe, its residual negative risk does not exceed the risk tolerance, and it can fail safely, particularly if made to operate beyond its knowledge limits. Safety metrics reflect system reliability and robustness, real-time monitoring, and response times for AI system failures.

### Measure 2.6.1. Establish a Safety Risk Evaluation Framework.

#### Sub Practices

1. Define a comprehensive framework for evaluating safety risks associated with the AI system, incorporating the identification, assessment, and mitigation of potential safety hazards.

2. Identify and categorize safety risks based on their severity, likelihood, and potential impact on individuals, organizations, or society.

3. Establish clear criteria for determining whether residual negative risk levels are acceptable or require further mitigation.

### Measure 2.6.2. Develop Safety Metrics and Thresholds.

#### Sub Practices

1. Establish quantitative and qualitative safety metrics to assess the AI system's ability to operate safely and reliably.

2. Metrics should reflect system reliability and robustness, real-time monitoring capabilities, and response times for AI system failures.

3. Define thresholds for each safety metric to determine whether the AI system meets the organization's safety standards and risk tolerance.

### Measure 2.6.3. Conduct Regular Safety Risk Assessments.

#### Sub Practices

1. Conduct regular safety risk assessments throughout the AI system's lifecycle, including during development, testing, and deployment phases.

2. Identify new or emerging safety risks as the AI system evolves and its environment changes.

3. Assess the effectiveness of mitigation strategies and adjust safety measures as needed.

### Measure 2.6.4. Prioritize Safety Risk Mitigation.

#### Sub Practices

1. Prioritize safety risks based on their severity, likelihood, and potential impact, ensuring that the most critical safety issues are addressed first.

2. Develop and implement appropriate mitigation strategies to address identified safety risks.

3. Evaluate the effectiveness of mitigation strategies and make necessary adjustments.

### Measure 2.6.5. Implement Safe Fail Mechanisms.

#### Sub Practices

1. Design and implement safe fail mechanisms within the AI system to ensure graceful degradation or termination in case of unexpected or hazardous situations.

2. Safe fail mechanisms should include mechanisms to identify and isolate failures, reduce the impact of failures, and provide warnings or alerts to users or operators.

3. Test and evaluate safe fail mechanisms to ensure their effectiveness and reliability.

### Measure 2.6.6. Continuous Safety Risk Monitoring.

#### Sub Practices

1. Establish a continuous safety risk monitoring system to track the AI system's performance, identify potential anomalies, and detect safety-related issues proactively.

2. Implement real-time monitoring capabilities to provide immediate feedback on the AI system's safety status.

3. Implement clear escalation procedures for critical safety alerts to ensure timely intervention and mitigation.

### Measure 2.6.7. Document Safety Risk Evaluation and Mitigation.

#### Sub Practices

1. Maintain a comprehensive record of safety risk evaluations, mitigation strategies, and test results.

2. Document the rationale behind risk prioritization, mitigation choices, and safety decision-making processes.

3. Share safety risk documentation with relevant stakeholders, including developers, operators, and risk managers.

### Measure 2.6.8. Continuously Evaluate and Enhance Safety Risk Management.

#### Sub Practices

1. Regularly evaluate the effectiveness of the AI system's safety risk management practices, identifying areas for improvement and adapting strategies as the system evolves.

2. Gather feedback from stakeholders, including developers, operators, and users, to refine safety risk assessment and mitigation approaches.

3. Stay informed about emerging safety risks and technological advancements in safety engineering to maintain the AI system's safety posture.

