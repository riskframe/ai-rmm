[//]: # (COPYRIGHT)
[//]: # (RiskFrame.ai - AI Risk Management and Resilience Framework)
[//]: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm)
[//]: # (SOFTWARE LICENSE)
[//]: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
    
## Manage 3.2
> Pre-trained models which are used for development are monitored as part of AI system regular monitoring and maintenance. [@playbook]

### Manage 3.2.1. Establish Pre-trained Model Inventory and Tracking.

Establishing a pre-trained model inventory and tracking system involves cataloging and monitoring the usage of pre-trained models utilized in the development of AI systems. This process includes documenting key information such as the origin, version, licensing agreements, and performance metrics of each pre-trained model. By maintaining an organized inventory and tracking system, organizations can ensure transparency, facilitate model governance, and streamline maintenance and updates, ultimately enhancing the reliability and effectiveness of their AI systems.

Cataloging and tracking pre-trained models involves compiling a comprehensive inventory of all models utilized in AI system development and deployment. This process entails documenting pertinent details such as source, version, purpose, and usage history for each model. Additionally, it involves implementing mechanisms, whether automated or manual, to monitor the lifecycle stages of these models, from creation to decommissioning, ensuring efficient management and oversight throughout.

#### Sub Practices

1. Create a comprehensive inventory of all pre-trained models used in the development and deployment of AI systems.

2. Maintain detailed records of each pre-trained model, including its source, purpose, version, and usage history.

3. Implement automated tools or manual processes to track the lifecycle of pre-trained models, including creation, deployment, updates, and decommissioning.

### Manage 3.2.2. Conduct Regular Monitoring of Pre-trained Model Performance.

Regular monitoring of pre-trained model performance is essential to ensure their continued effectiveness and reliability within AI systems. This process involves systematically assessing key performance metrics, such as accuracy, latency, and model drift, to identify any deviations or deterioration in performance. By conducting ongoing monitoring, organizations can promptly detect and address issues, such as concept drift or data biases, that may arise over time. Additionally, this proactive approach enables timely interventions, such as retraining or updating models, to maintain optimal performance and mitigate potential risks to AI system functionality and outcomes.

Establishing ongoing monitoring mechanisms is crucial for tracking the performance, accuracy, and fairness of pre-trained models. These mechanisms operate in real-time or at regular intervals, leveraging analytics tools, performance metrics, and user feedback to detect anomalies, degradation, or biases in model behavior. By proactively identifying and addressing potential issues before they impact AI system performance or stakeholder trust, organizations can maintain the reliability and effectiveness of their deployed models.

#### Sub Practices

1. Establish ongoing monitoring mechanisms to track the performance, accuracy, and fairness of pre-trained models in real-time or at regular intervals.

2. Utilize analytics tools, performance metrics, and user feedback to detect anomalies, degradation, or biases in model behavior.

3. Proactively identify and address potential issues before they impact AI system performance or stakeholder trust.

### Manage 3.2.3. Implement Continuous Verification and Validation.

Implementing continuous verification and validation processes is essential for ensuring the ongoing reliability and effectiveness of pre-trained models used in AI systems. These processes involve continuously assessing the performance, accuracy, and fairness of the models through various techniques such as data validation, cross-validation, and bias detection. By regularly verifying and validating pre-trained models, organizations can identify and mitigate potential issues promptly, maintain model integrity, and uphold trustworthiness in AI applications.

Regularly verifying and validating the accuracy, fairness, and robustness of pre-trained models against updated datasets and usage scenarios is crucial for ensuring their reliability and effectiveness. Employing data validation techniques, bias detection algorithms, and robustness testing frameworks allows organizations to assess model performance under diverse conditions, mitigating potential issues and upholding trust in AI systems. Documenting the results of verification and validation activities facilitates tracking trends, identifying areas for improvement, and making informed decisions about model maintenance or replacement.

#### Sub Practices

1. Regularly verify and validate the accuracy, fairness, and robustness of pre-trained models against updated datasets and usage scenarios.

2. Employ data validation techniques, bias detection algorithms, and robustness testing frameworks to assess model performance under varying conditions.

3. Document the results of verification and validation activities to track trends, identify areas for improvement, and make informed decisions about model maintenance or replacement.

### Manage 3.2.4. Manage Pre-trained Model Updates and Updates.

To effectively manage pre-trained model updates and maintenance, organizations should establish clear procedures and protocols for identifying, evaluating, and implementing updates. This includes monitoring for new versions, patches, or improvements released by the model provider, assessing their impact on system performance and functionality, and determining the appropriate timing for deployment. Additionally, organizations should ensure proper testing and validation of updated models to mitigate any potential risks or disruptions to AI systems. Regularly documenting and documenting these processes ensures accountability and facilitates continuous improvement in model management practices.

Managing and updating pre-trained models involves establishing a structured process to ensure their ongoing relevance and effectiveness. This includes proactively identifying and applying updates released by model developers or providers to address known issues, improve performance, or adapt to new data. Testing and validating updated models before integration into AI systems are crucial steps in minimizing the risk of introducing new problems or performance degradation.

#### Sub Practices

1. Establish a process for managing and updating pre-trained models to ensure their continued relevance and effectiveness.

2. Proactively identify and apply updates released by model developers or providers to address known issues, improve performance, or adapt to new data.

3. Test and validate updated models before integrating them into AI systems to minimize the risk of introducing new problems or performance degradation.

### Manage 3.2.5. Establish Decommissioning Procedures for Pre-trained Models.

Establishing decommissioning procedures for pre-trained models is essential to ensure the effective management of AI risks and benefits. These procedures should outline clear steps for retiring outdated or underperforming models, including data migration, system updates, and stakeholder communication. Additionally, it's important to document the reasons for decommissioning each model and ensure proper disposal of associated data to maintain compliance with privacy regulations. Regular review and updating of decommissioning procedures are necessary to adapt to evolving technology and mitigate potential risks associated with outdated models.

Implementing procedures for decommissioning outdated or unused pre-trained models is crucial for maintaining AI system efficiency and security. These procedures involve documenting and following clear steps to remove such models from the system, ensuring proper disposal of associated data. Tracking the decommissioning process ensures that no outdated models remain in use, minimizing security risks and optimizing system performance.

#### Sub Practices

1. Develop and implement procedures for decommissioning and removing outdated or unused pre-trained models from AI systems.

2. Ensure that decommissioning procedures are documented and adhered to to maintain system efficiency and reduce potential security risks.

3. Track the decommissioning of pre-trained models to ensure that they are no longer in use and that their associated data is properly secured and disposed of.

### Manage 3.2.6. Foster a Culture of Pre-trained Model Awareness.

Fostering a culture of pre-trained model awareness entails educating stakeholders within the organization about the significance of pre-trained models in AI development and deployment. This involves raising awareness about the benefits, limitations, and potential risks associated with using pre-trained models. By promoting understanding and transparency regarding the role of pre-trained models, stakeholders can make informed decisions and contribute effectively to the monitoring and maintenance of AI systems.

Highlighting the importance of managing pre-trained models responsibly involves educating AI developers, operators, and stakeholders about the risks associated with outdated or unsupported models. By integrating pre-trained model management practices into organizational policies, procedures, and training programs, a culture of continuous improvement and risk mitigation can be fostered, ensuring the reliability and effectiveness of AI systems.

#### Sub Practices

1. Educate AI developers, operators, and stakeholders about the importance of managing pre-trained models responsibly.

2. Highlight the potential risks associated with using outdated or unsupported models, such as performance degradation, bias, and security vulnerabilities.

3. Integrate pre-trained model management practices into organizational policies, procedures, and training programs to promote a culture of continuous improvement and risk mitigation.

### Manage 3.2 Suggested Work Products

* Pre-trained Model Inventory and Tracking Database - A centralized database documenting key information about pre-trained models, including their origin, version, licensing agreements, and performance metrics.
* Regular Monitoring Reports - Reports detailing the ongoing monitoring of pre-trained model performance, including assessments of accuracy, latency, and potential drift, with insights into any deviations or deteriorations observed.
* Continuous Verification and Validation Framework - A framework outlining the processes and techniques for continuously verifying and validating pre-trained models, ensuring their reliability, accuracy, and fairness over time.
* Model Update and Maintenance Procedures Documentation - Documentation describing the procedures and protocols for managing updates and maintenance of pre-trained models, including steps for identifying, evaluating, and implementing updates.
* Decommissioning Procedures - Procedures outlining the steps for decommissioning outdated or underperforming pre-trained models, including data migration, system updates, and stakeholder communication plans.
* Model Performance Reports - Reports analyzing the performance of pre-trained models over time, highlighting trends, anomalies, and areas for improvement, based on continuous monitoring and validation activities.
* Stakeholder Communication Plan - A communication plan detailing how stakeholders will be informed about pre-trained model updates, performance issues, and decommissioning decisions, ensuring transparency and accountability.
* Data Privacy Compliance Documentation - Documentation ensuring compliance with data privacy regulations during the management of pre-trained models, including procedures for data anonymization, encryption, and secure disposal.
* Continuous Improvement Plan - A plan outlining initiatives for continuously improving pre-trained model management practices, including regular reviews, updates, and enhancements to monitoring, validation, and decommissioning processes.
