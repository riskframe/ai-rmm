[//]: # (COPYRIGHT)
[//]: # (RiskFrame.ai - AI Risk Management and Resilience Framework)
[//]: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm)
[//]: # (SOFTWARE LICENSE)
[//]: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
    
## Measure 1.3
> Internal experts who did not serve as front-line developers for the system and/or independent assessors are involved in regular assessments and updates. Domain experts, users, AI actors external to the team that developed or deployed the AI system, and affected communities are consulted in support of assessments as necessary per organizational risk tolerance. [@playbook]

### Measure 1.3.1. Engage Internal and External Expertise.

This practice involves leveraging the insights and perspectives of domain experts, users, and AI actors external to the development team in regular assessments and updates of AI systems. By tapping into a diverse range of expertise, organizations can gain valuable insights into potential risks, identify areas for improvement, and ensure that assessments align with organizational risk tolerance levels. Such a collaborative approach fosters a more comprehensive understanding of AI system impacts and enhances the effectiveness of risk management strategies.

Engaging internal experts who were not directly involved in the AI system's development provides independent perspectives and assessments. Collaborating with independent assessors or consultants skilled in AI governance, risk management, and responsible AI practices enhances assessment effectiveness. Establishing a process for selecting and onboarding external assessors ensures their competence, impartiality, and adherence to ethical principles.

#### Sub Practices

1. Regularly involve internal experts who did not directly participate in the AI system's development to provide independent perspectives and assessments.

2. Collaborate with independent assessors or consultants with expertise in AI governance, risk management, and responsible AI practices.

3. Establish a process for selecting and onboarding external assessors, ensuring their competence, impartiality, and adherence to ethical principles.

### Measure 1.3.2. Consult with Domain Experts and Users.

Consulting with domain experts and users plays a crucial role in gaining insights into the real-world application and impacts of AI systems. By leveraging the expertise of domain specialists and engaging with end-users, organizations can ensure that assessments consider relevant contextual factors and user experiences. This practice facilitates a holistic understanding of the AI system's performance, usability, and potential implications within specific domains or user communities, enabling more informed decision-making and risk management processes.

Seeking input from domain experts with deep knowledge of the AI system's application domain, engaging with actual users to understand their experiences, feedback, and concerns, and establishing clear channels for feedback and collaboration are essential sub-practices for involving domain experts and users in assessments.

#### Sub Practices

1. Seek input from domain experts with deep knowledge of the AI system's application domain to assess its relevance, effectiveness, and potential impacts.

2. Engage with actual users of the AI system to understand their experiences, feedback, and concerns related to its performance, trustworthiness, and ethical implications.

3. Establish clear channels for feedback and collaboration with users, ensuring their voices are heard and incorporated into the assessment process.

### Measure 1.3.3. Involve AI Actors and Affected Communities.

Engaging AI actors and affected communities in assessments is crucial for gaining diverse perspectives and insights into the AI system's impacts and effectiveness. By involving AI actors, such as developers, researchers, and policymakers, organizations can leverage their expertise to evaluate the system's performance and identify potential risks or opportunities for improvement. Similarly, consulting with affected communities allows for understanding their unique needs, concerns, and experiences with the AI system, ensuring that assessments consider their perspectives and prioritize their well-being.

Involving AI actors external to the development team, such as researchers, ethicists, and industry experts, brings diverse perspectives to assessing the AI system's trustworthiness and potential impacts. Consulting with representatives of affected communities, who may face unique vulnerabilities from the AI system's decisions or outputs, ensures their voices are heard and their concerns addressed. Establishing mechanisms for open and respectful engagement with AI actors and affected communities prioritizes their perspectives, fostering collaboration and trust in the assessment process.

#### Sub Practices

1. Collaborate with AI actors external to the development team, such as researchers, ethicists, and industry experts, to gain diverse perspectives on the AI system's trustworthiness and potential impacts.

2. Consult with representatives of affected communities who may be particularly vulnerable to the AI system's decisions or outputs.

3. Establish mechanisms for open and respectful engagement with AI actors and affected communities, prioritizing their concerns and perspectives.

### Measure 1.3.4. Tailor Assessment Involvement to Risk Tolerance.

Adapting the level of involvement in assessments to match organizational risk tolerance involves customizing the engagement of internal and external stakeholders based on the perceived risks and potential impacts of the AI system. This tailored approach ensures that the right experts and stakeholders are consulted to provide insights and perspectives aligned with the organization's risk management strategy. By calibrating the degree of involvement according to risk tolerance levels, organizations can effectively manage and mitigate risks while optimizing resources and expertise.

Prioritizing the involvement of external experts and stakeholders based on the organization's risk tolerance and the perceived severity of AI risks associated with the system entails tailoring the level of engagement to match the specific risk profiles. This tailored approach ensures that resources are allocated effectively, with more extensive involvement for AI systems with higher-risk profiles and selective engagement for those with lower-risk profiles. By calibrating involvement based on risk tolerance levels, organizations can optimize the assessment process while effectively managing potential risks and impacts.

#### Sub Practices

1. Prioritize the involvement of external experts and stakeholders based on the organization's risk tolerance and the perceived severity of AI risks associated with the system.

2. For AI systems with high-risk profiles, engage a wider range of external experts and consult with affected communities more extensively.

3. For AI systems with lower-risk profiles, involve internal experts and selectively consult with domain experts and users.

### Measure 1.3.5. Document Assessment Involvement and Seek Clear Roles.

This practice involves creating comprehensive records of the individuals and groups engaged in the assessment process, along with their respective roles and responsibilities. This documentation ensures transparency and accountability, facilitating effective communication and coordination among stakeholders. By clarifying roles and responsibilities upfront, organizations can streamline the assessment process, minimize misunderstandings, and optimize resource allocation. Additionally, documenting assessment involvement provides a valuable reference for future assessments and enables organizations to track the evolution of their risk management practices over time.

Documenting the involvement of internal and external experts, domain experts, users, AI actors, and affected communities in the assessment process ensures transparency and accountability. Assigning clear roles and responsibilities to each participant facilitates effective coordination and utilization of their contributions. Maintaining a record of consultations and feedback, including summarized insights and recommendations from each source, enables organizations to track the assessment process comprehensively and incorporate valuable insights into their risk management strategies.

#### Sub Practices

1. Clearly document the involvement of internal and external experts, domain experts, users, AI actors, and affected communities in the assessment process.

2. Assign clear roles and responsibilities to each participant, ensuring their contributions are effectively coordinated and utilized.

3. Maintain a record of consultations and feedback, including summarized insights and recommendations from each source.

### Measure 1.3.6. Continuously Evaluate and Adapt Assessment Approach.

Continuously evaluating and adapting the assessment approach involves regularly reviewing the effectiveness of the current assessment methods and making adjustments as needed to address evolving risks and stakeholder needs. This process includes gathering feedback from stakeholders and experts to identify areas for improvement and experimenting with new approaches or methodologies to enhance the assessment process. By remaining flexible and responsive, organizations can ensure that their assessment approach remains relevant and effective in mitigating AI risks and promoting trustworthiness.

This practice requires periodically assessing the efficacy of current methods and soliciting feedback from participants on their experiences and contributions. By gathering insights on the effectiveness of the assessment process and the level of engagement from external experts and stakeholders, organizations can identify opportunities for improvement and adapt their approach to better meet the needs of all involved parties.

#### Sub Practices

1. Regularly evaluate the effectiveness of the assessment approach and the level of involvement of external experts and stakeholders.

2. Seek feedback from participants on the assessment process and their perceived contribution to the overall assessment outcomes.

### Measure 1.3 Suggested Work Products

* Independent Expert Review Report - Documentation of assessments conducted by internal experts not involved in the development of the AI system, detailing their findings and recommendations.
* External Assessor Engagement Plan - A comprehensive plan outlining the process for selecting, onboarding, and collaborating with external assessors, including criteria for their competence and impartiality.
* User Experience Feedback Summary - A compiled report summarizing feedback, concerns, and suggestions collected from actual users of the AI system, highlighting areas for improvement.
* Domain Expert Consultation Records - Detailed records of consultations with domain experts, capturing their insights on the AI system's relevance, effectiveness, and potential domain-specific impacts.
* Community Engagement Report - A report detailing the process and outcomes of engaging with affected communities, including their feedback, concerns, and how these have been addressed in the AI system's assessment and updates.
* Risk Tolerance Alignment Documentation - Documentation that outlines how the level of expert and stakeholder involvement in AI assessments is tailored based on the organization's risk tolerance and the AI system's risk profile.
* Assessment Methodology Evolution Log - A log that tracks changes and adaptations made to the assessment methodology over time, including reasons for changes and the effectiveness of new approaches.
* Stakeholder Feedback and Adaptation Record - A document that captures stakeholder feedback on the assessment process and documents how the assessment approach has been adapted in response to this feedback.
