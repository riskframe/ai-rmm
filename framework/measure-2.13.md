[//]: # (COPYRIGHT)
[//]: # (RiskFrame.ai - AI Risk Management and Resilience Framework)
[//]: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm)
[//]: # (SOFTWARE LICENSE)
[//]: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
    
## Measure 2.13: Effectiveness of the employed TEVV metrics and processes in the measure function are evaluated and documented.

### Measure 2.13.1. Evaluate TEVV Metric Effectiveness.

#### Sub Practices

1. Regularly evaluate the effectiveness of the employed TEVV metrics in assessing the trustworthiness, explainability, validity, and value of the AI system.

2. Assess whether the chosen metrics are relevant, measurable, and capable of capturing the key aspects of AI trustworthiness.

3. Identify potential gaps or limitations in the existing metrics and consider refining or adapting them as needed.

### Measure 2.13.2. Evaluate TEVV Process Effectiveness.

#### Sub Practices

1. Evaluate the effectiveness of the employed TEVV processes in collecting, analyzing, and interpreting data related to the AI system's trustworthiness, explainability, validity, and value.

2. Assess whether the processes are efficient, scalable, and aligned with the organization's risk tolerance and decision-making processes.

3. Identify potential bottlenecks or inefficiencies in the processes and consider streamlining or automating them as appropriate.

### Measure 2.13.3. Document TEVV Evaluation Findings.

#### Sub Practices

1. Maintain a comprehensive record of TEVV metric evaluation findings, including the identified strengths, weaknesses, and recommendations for improvement.

2. Document the rationale behind metric selection and evaluation processes, ensuring transparency and traceability of decisions.

3. Share TEVV evaluation documentation with relevant stakeholders to promote knowledge sharing and continuous improvement.

### Measure 2.13.4. Incorporate TEVV Feedback into Decision-Making.

#### Sub Practices

1. Utilize TEVV evaluation findings to inform decision-making throughout the AI development lifecycle, including design, development, testing, deployment, and operations.

2. Use insights from TEVV metrics to prioritize risks, identify areas for improvement, and make informed decisions about the AI system's trustworthiness, explainability, validity, and value.

3. Establish clear communication channels to ensure that TEVV feedback is effectively communicated to stakeholders and incorporated into decision-making processes.

### Measure 2.13.5. Continuously Improve TEVV Metrics and Processes.

#### Sub Practices

1. Regularly review and update the employed TEVV metrics and processes based on lessons learned, emerging best practices, and evolving AI technologies.

2. Gather feedback from internal and external stakeholders, including AI developers, operators, users, and regulatory bodies, to refine TEVV practices.

3. Stay informed about emerging research, standards, and guidelines related to TEVV for AI systems to ensure the effectiveness of TEVV metrics and processes.

### Measure 2.13.6. Foster TEVV Culture.

#### Sub Practices

1. Cultivate a culture of TEVV awareness and responsibility throughout the organization, embedding trustworthiness, explainability, validity, and value into AI development practices.

2. Educate and train AI developers, operators, and decision-makers on TEVV principles, metrics, and processes.

3. Integrate TEVV considerations into organizational policies, procedures, and governance frameworks to ensure ongoing TEVV assessment.

