[//]: # (COPYRIGHT)
[//]: # (RiskFrame.ai - AI Risk Management and Resilience Framework)
[//]: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm)
[//]: # (SOFTWARE LICENSE)
[//]: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
    
## Manage 2.4: Mechanisms are in place and applied, and responsibilities are assigned and understood, to supersede, disengage, or deactivate AI systems that demonstrate performance or outcomes inconsistent with intended use.

### Manage 2.4.1. Establish a Disengagement and Deactivation Framework.

#### Sub Practices

1. Develop a comprehensive framework to guide the process of disengaging or deactivating AI systems that demonstrate performance or outcomes inconsistent with intended use.

2. The framework should clearly define roles and responsibilities, decision-making criteria, and procedures for taking appropriate actions.

### Manage 2.4.2. Identify and Assess Potential Disengagement Scenarios.

#### Sub Practices

1. Proactively identify potential scenarios that may warrant the disengagement or deactivation of AI systems, such as severe performance degradation, biased outcomes, or ethical violations.

2. Assess the likelihood and potential impact of each scenario to prioritize mitigation strategies and preparedness efforts.

3. Document these scenarios and their associated risks to inform decision-making and resource allocation.

### Manage 2.4.3. Establish Clear Disengagement Criteria.

#### Sub Practices

1. Define clear and objective criteria for determining when to disengage or deactivate an AI system due to performance or outcome inconsistencies.

2. These criteria should consider factors such as the severity and potential impact of the issue, the feasibility of mitigation measures, and the overall risk to stakeholders.

3. Regularly review and refine the disengagement criteria to reflect evolving risk profiles and technological advancements.

### Manage 2.4.4. Assign Disengagement and Deactivation Responsibilities.

#### Sub Practices

1. Clearly define roles and responsibilities for initiating, evaluating, and authorizing the disengagement or deactivation of AI systems.

2. Establish a clear chain of command for making such decisions, ensuring that it aligns with the organizational structure and decision-making processes.

3. Assign specific individuals or teams with the authority to make disengagement or deactivation decisions, ensuring they have the necessary expertise and accountability.

### Manage 2.4.5. Implement Prompt and Effective Disengagement Procedures.

#### Sub Practices

1. Develop and implement procedures for promptly disengaging or deactivating AI systems when the need arises.

2. These procedures should clearly outline the steps to be taken, including notification of relevant stakeholders, documentation of the reasons for disengagement, and coordination with other affected systems or processes.

3. Regularly test and refine the disengagement procedures to ensure their effectiveness and adaptability to new scenarios.

### Manage 2.4.6. Maintain Transparency and Accountability.

#### Sub Practices

1. Communicate clearly and transparently to stakeholders when an AI system is disengaged or deactivated due to performance or outcome inconsistencies.

2. Provide a clear explanation of the reasons for the action, the potential impact on stakeholders, and the steps being taken to address the issue.

3. Document disengagement or deactivation events and their associated justifications to maintain accountability and facilitate learning from past experiences.

### Manage 2.4.7. Foster a Culture of Responsible AI Development and Deployment.

#### Sub Practices

1. Promote a culture of responsible AI development and deployment throughout the organization.

2. Educate AI developers, operators, and stakeholders about the importance of system trustworthiness, ethical considerations, and the need for proactive disengagement or deactivation mechanisms.

3. Integrate these principles into organizational policies, procedures, and training programs to ensure a holistic approach to AI safety and accountability.

