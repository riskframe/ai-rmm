[//]: # (COPYRIGHT)
[//]: # (RiskFrame.ai - AI Risk Management and Resilience Framework)
[//]: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm)
[//]: # (SOFTWARE LICENSE)
[//]: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
    
## Measure 2.4: The functionality and behavior of the AI system and its components – as identified in the map function – are monitored when in production.

### Measure 2.4.1. Establish Monitoring Requirements and Objectives.

#### Sub Practices

1. Define clear and comprehensive monitoring requirements that encompass the AI system's functionality, performance, and trustworthiness characteristics as identified in the Map function.

2. Establish objectives for monitoring activities, including identifying potential issues, detecting anomalies, and ensuring adherence to performance or assurance criteria.

3. Document the monitoring requirements and objectives, ensuring they are aligned with organizational risk tolerance and the AI system's intended purpose.

### Measure 2.4.2. Select Appropriate Monitoring Tools and Technologies.

#### Sub Practices

1. Identify and select appropriate monitoring tools and technologies that can effectively collect, analyze, and correlate data related to the AI system's behavior.

2. Consider factors such as data volume, real-time processing capabilities, and integration with existing IT infrastructure when selecting tools.

3. Evaluate the capabilities and limitations of monitoring tools, ensuring they can effectively capture and analyze the AI system's relevant characteristics.

### Measure 2.4.3. Implement Monitoring Infrastructure and Processes.

#### Sub Practices

1. Establish a dedicated monitoring infrastructure that can collect, store, and analyze data from the AI system and its components.

2. Develop and implement monitoring processes that define the frequency of data collection, analysis intervals, and alert mechanisms.

3. Integrate monitoring tools and infrastructure into the AI system's development lifecycle, ensuring continuous monitoring from the deployment stage onwards.

### Measure 2.4.4. Collect and Analyze Monitoring Data.

#### Sub Practices

1. Continuously collect data from the AI system and its components, including logs, metrics, and performance indicators.

2. Analyze collected data using appropriate tools and techniques to identify anomalies, potential issues, and deviations from expected behavior.

3. Correlate data across different sources to gain a holistic understanding of the AI system's overall performance and trustworthiness.

### Measure 2.4.5. Generate and Respond to Monitoring Alerts.

#### Sub Practices

1. Establish a system for generating and prioritizing alerts based on the severity and impact of potential issues detected during monitoring.

2. Define clear escalation procedures for critical alerts, ensuring timely notification of relevant stakeholders and decision-makers.

3. Implement incident response plans to address identified issues, remediate vulnerabilities, and prevent further occurrences.

### Measure 2.4.6. Document Monitoring Activities and Findings.

#### Sub Practices

1. Maintain a comprehensive record of monitoring activities, including data collection logs, analysis results, and incident responses.

2. Document findings from monitoring activities, including potential issues, corrective actions taken, and lessons learned.

3. Share monitoring reports and findings with relevant stakeholders to promote transparency and informed decision-making.

### Measure 2.4.7. Continuously Evaluate and Improve Monitoring.

#### Sub Practices

1. Regularly evaluate the effectiveness of monitoring activities, identifying areas for improvement and adapting monitoring requirements.

2. Gather feedback from stakeholders, including developers, operators, and risk managers, to refine monitoring strategies and address gaps in coverage.

3. Adopt emerging monitoring technologies and methodologies to ensure the AI system remains adequately monitored and its trustworthiness maintained.

