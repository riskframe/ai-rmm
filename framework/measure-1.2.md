[//]: # (COPYRIGHT)
[//]: # (RiskFrame.ai - AI Risk Management and Resilience Framework)
[//]: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm)
[//]: # (SOFTWARE LICENSE)
[//]: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
    
## Measure 1.2: Appropriateness of AI metrics and effectiveness of existing controls are regularly assessed and updated, including reports of errors and potential impacts on affected communities.

### Measure 1.2.1. Regularly Evaluate Measurement Approach Relevance.

#### Sub Practices

1. Periodically assess the continued relevance of the selected measurement approaches and metrics in light of the AI system's evolution and changing context.

2. Evaluate the ability of existing metrics to capture the evolving nature of AI risks and the effectiveness of mitigation strategies.

3. Identify potential blind spots or limitations in the current measurement approach and consider incorporating new metrics or methodologies.

### Measure 1.2.2. Analyze Error Reports and Identify Impacts.

#### Sub Practices

1. Establish a mechanism for collecting, analyzing, and tracking reports of AI errors, biases, or unintended consequences.

2. Analyze error reports to identify patterns, trends, and potential impacts on affected communities.

3. Proactively investigate and address reported errors to minimize their negative impact and refine the AI system's performance and trustworthiness.

### Measure 1.2.3. Assess Effectiveness of Existing Controls.

#### Sub Practices

1. Regularly evaluate the effectiveness of existing controls in mitigating AI risks and preventing errors or unintended consequences.

2. Analyze data collected through measurement processes to assess the effectiveness of controls in addressing identified risks.

3. Identify areas where existing controls may be insufficient or ineffective and consider implementing additional or enhanced mitigation strategies.

### Measure 1.2.4. Integrate Evaluation Findings into Risk Management.

#### Sub Practices

1. Incorporate the findings from measurement evaluations and error reports into the AI system's risk management process.

2. Use the insights gained to update risk assessments, prioritize mitigation efforts, and refine risk management strategies.

3. Communicate evaluation findings to relevant stakeholders to promote transparency and accountability in AI governance.

### Measure 1.2.5. Continuously Improve Measurement and Control Strategies.

#### Sub Practices

1. Maintain a culture of continuous improvement by regularly evaluating and refining measurement approaches and control strategies.

2. Gather feedback from stakeholders, experts, and data analysts to identify areas for improvement and emerging risk profiles.

3. Adapt measurement processes, metrics, and control mechanisms based on the evaluation findings and evolving AI system landscape.

