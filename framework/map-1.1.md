[//]: # (COPYRIGHT)
[//]: # (RiskFrame.ai - AI Risk Management and Resilience Framework)
[//]: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm)
[//]: # (SOFTWARE LICENSE)
[//]: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
    
# Map 1: Context is established and understood.

## Map 1.1: Intended purposes, potentially beneficial uses, context-specific laws, norms and expectations, and prospective settings in which the AI system will be deployed are understood and documented. Considerations include: the specific set or types of users along with their expectations; potential positive and negative impacts of system uses to individuals, communities, organizations, society, and the planet; assumptions and related limitations about AI system purposes, uses, and risks across the development or product AI lifecycle; and related Test, Evaluation, Verification, and Validation (TEVV) and system metrics.

### Map 1.1.1. Clearly Define Intended Purposes and Beneficial Uses.

The formal delineation of primary objectives, functions, and advantageous outcomes of the AI system must be undertaken while conscientiously considering ethical, legal, and societal norms. This necessitates the explicit definition of tasks and services the AI system will execute and the comprehensive documentation of potential favorable impacts on users, communities, and society at large. Furthermore, it mandates a profound comprehension of user requirements, system constraints, and associated risks. The establishment of evaluation criteria and metrics is vital to ensure effectiveness, efficiency, and fairness in operation. Continuous monitoring is essential to guarantee alignment with evolving expectations, this systematic approach ensures an evident comprehension of the AI system's intended objectives and its beneficial applications throughout its lifecycle.

It is of crucial to develop a comprehensive documentation that articulates the intended functionalities of the AI system with precision. This involves the specific advantages that the system aims to deliver to its users, organizations, and broader societal contexts. Additionally, ensuring alignment between the objectives and beneficial applications of the AI system with the overarching strategic goals and objectives of the organization is essential. Such alignment fosters coherence and synergy between the functionalities of the AI system and the broader mission and vision of the organization, thereby facilitating more effective and purpose-driven implementation and utilization of AI technologies.

#### Sub Practices

1. Establish clear and concise documentation of the intended purposes of the AI system.

2. Identify the specific benefits that the AI system aims to achieve for its users, organizations, and society.

3. Align intended purposes and beneficial uses with the organization's overall strategic goals and objectives.

### Map 1.1.2. Identify Context-Specific Laws, Norms, and Expectations.

Thorough examination of legal data protection frameworks and industry regulations, in conjunction with comprehension of societal norms, ethical precepts, and user expectations, is essential. Organizations are required to actively involve diverse user cohorts to collect insights pertaining to preferences and apprehensions, thereby ensuring alignment with user needs through user-centered AI system design principles.

Developing an AI system necessitates a thorough examination encompassing legal, regulatory, ethical, and societal considerations pertinent to its proposed application. Complying with legal and regulatory guidelines ensures conformity to accepted norms and reduces legal liabilities. Evaluating ethical implications cultivates trust and openness in AI systems, vital for gaining acceptance from users and stakeholders. Moreover, taking into account cultural and societal contexts aids in foreseeing potential societal repercussions and ensures harmony with prevailing values and norms. Ultimately, these procedures facilitate the responsible advancement and implementation of AI technology, promoting ethical conduct and mitigating potential adverse effects.

#### Sub Practices

1. Conduct a thorough analysis of the legal, regulatory, ethical, and social norms relevant to the AI system's intended use.

2. Assess potential ethical considerations, such as fairness, bias, and privacy, in the context of the AI system's operation.

3. Consider the cultural and societal context in which the AI system will be deployed.

### Map 1.1.3. Define Prospective Deployment Settings.

The deployment settings encompass the environment in which the system is intended to operate, including its intended use, geographic locations, network infrastructure, and anticipated user base. Understanding these deployment settings is important for assessing risks, implementing security controls, and ensuring the system's resilience against potential threats and vulnerabilities. Through defining the prospective deployment settings, organizations can strategically plan and tailor risk management approaches to safeguard the AI system's integrity, confidentiality, and availability throughout its lifecycle.

Prospective deployment settings of an AI system encompass a thorough consideration of various interrelated factors to ensure its successful integration and operation within its intended environment. From a technical standpoint, it involves configuring the necessary hardware and software components, ensuring they align with the expected infrastructure design and can accommodate potential scalability needs, assessed for quality, and secured to maintain privacy and regulatory compliance. Operationally, the AI system should seamlessly integrate into existing workflows, with protocols established for maintenance, monitoring, and disaster recovery to sustain optimal performance. Additionally, the user environment must inform interface design and contextual adaptation, enabling the AI system to effectively respond to varying conditions and user needs. By addressing these dimensions comprehensively, organizations can mitigate risks, optimize performance, and maximize the value derived from AI deployments while upholding ethical and regulatory standards.

#### Sub Practices

1. Clearly define the specific environments and settings where the AI system will be deployed.

2. Consider factors such as user demographics, technical infrastructure, and operational requirements.

3. Identify potential interactions with other systems or data sources in the deployment environment.

### Map 1.1.4. Understand User Expectations and Impacts.

In the current landscape of technology, comprehending user expectations serves as a cornerstone for organizations striving to design and implement AI systems that resonate with user requirements while strategically navigating associated risks. The importance to discern user expectations underscores a broader objective of aligning AI technologies with user-centric principles, thereby fostering user satisfaction and trust. Moreover, alongside gauging user expectations, an equally critical endeavour involves evaluating the multifaceted impacts of AI systems on individuals, organizations, and society at large. Organizations must aim to facilitate the identification and mitigation of potential risks inherent in AI deployments, ensuring that technological advancements remain consonant with ethical imperatives and societal values. By prioritizing user expectations and proactively addressing the ramifications of AI implementations, organizations engender a culture of responsible innovation, thereby bolstering trust and advancing the ethical contours of AI development and deployment practices.

Engaging in thorough user research serves as a fundamental step in understanding the complex expectations, needs, and worries of the target users of the AI system. This approach not only helps AI developers customize the system to effectively meet user demands but also deepens insight into user preferences and challenges. Recognizing both the positive and negative impacts of the AI system on various stakeholders such as individuals, communities, organizations, society, and the environment is essential. By carefully evaluating these impacts, organizations can anticipate and mitigate potential risks while maximizing the system's benefits for everyone involved.
A vital aspect of responsible AI development involves proactively assessing the potential for unintended consequences and ethical concerns arising from the system's functionality. This underscores the significance of pre-emptively recognizing and addressing ethical dilemmas, biases, and privacy issues ingrained within the system's design and operation, thereby upholding ethical standards and advancing societal welfare. Ultimately, it reflects a dedication to ethical and responsible innovation within the AI domain.

#### Sub Practices

1. Conduct user research to understand the expectations, needs, and concerns of the AI system's target users.

2. Identify potential positive and negative impacts of the AI system on individuals, communities, organizations, society, and the planet.

3. Assess the potential for unintended consequences and ethical concerns arising from the AI system's operation.

### Map 1.1.5. Document Assumptions, Limitations, and TEVV.

It is essential to establish a comprehensive understanding of the AI system's underlying principles and operational boundaries. This entails documenting the assumptions driving the system's design and functionality, as well as recognizing its inherent limitations. Through meticulous documentation, AI system developers gain clarity on the foundational beliefs shaping the AI system's development and operation. Moreover, a thorough process of Testing, Evaluation, Verification, and Validation (TEVV) ensures that the system behaves as intended, meets specified requirements, and operates reliably across diverse scenarios.

These components collectively serve as foundational pillars, outlining the limits, capabilities, and ethical considerations inherent in the AI system's operational structure. Assumptions encapsulate the foundational beliefs underpinning system design and functionality, while limitations define the boundaries within which the system functions. TEVV processes, encompassing testing, evaluation, verification, and validation, ensure the system's adherence to predefined standards, its efficacy in diverse scenarios, and its alignment with user expectations and regulatory requirements. Such documentation not only promotes transparency and accountability but also facilitates well-informed decision-making throughout the AI system's lifecycle, thus encouraging responsible and ethical AI development and deployment practices.

#### Sub Practices

1. Clearly document the assumptions and limitations related to the AI system's intended purposes, uses, and risks.

2. Outline the Test, Evaluation, Verification, and Validation (TEVV) strategy for ensuring the AI system's reliability, performance, and compliance with requirements.

3. Define system metrics to measure the effectiveness and impact of the AI system.

### Map 1.1.6. Conduct Continuous Mapping Throughout the AI Lifecycle.

This approach emphasizes the importance of consistently evaluating and modifying essential components throughout every phase of the AI lifecycle, starting from the initial idea to deployment and maintenance. Through continuous mapping, professionals actively evaluate different aspects of AI projects such as data collection, preprocessing techniques, model training, assessment criteria, deployment approaches, and continuous monitoring. This cyclic process guarantees that AI systems not only achieve their performance goals but also comply with ethical guidelines, regulatory standards, and changing user demands throughout their lifecycle.

Implementing a structured methodology for consistently evaluating and revising key aspects of AI projects from their inception to ongoing maintenance. AI stakeholders engage in continual mapping to navigate the dynamic landscape of AI technology, addressing intended functionalities, positive applications, context-specific considerations, and underlying assumptions guiding the development process. This proactive approach encourages transparency, responsibility, and adherence to ethical guidelines, regulatory standards, and changing user requirements. By regularly reassessing and updating the understanding of intended functionalities, positive applications, context-specific considerations, and assumptions as the AI system progresses; adjusting Test, Evaluation, Validation, and Verification (TEVV) strategies and performance metrics to accommodate alterations in the AI system's design, development, and deployment; and maintaining a centralized repository to document all mapping details and ensure accessibility for relevant stakeholders. This facilitates collaboration, knowledge exchange, and informed decision-making throughout various phases of the AI lifecycle, thereby improving the overall efficiency and accountability of AI endeavors.

#### Sub Practices

1. Regularly review and update the understanding of intended purposes, beneficial uses, context-specific considerations, and assumptions as the AI system evolves.

2. Adapt TEVV plans and system metrics to reflect changes in the AI system's design, development, and deployment.

3. Maintain a centralized repository to document all mapping information and ensure accessibility for relevant stakeholders.

