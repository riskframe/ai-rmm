[//]: # (COPYRIGHT)
[//]: # (RiskFrame.ai - AI Risk Management and Resilience Framework)
[//]: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm)
[//]: # (SOFTWARE LICENSE)
[//]: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
    
# Measure 1: Appropriate methods and metrics are identified and applied.

## Measure 1.1: Approaches and metrics for measurement of AI risks enumerated during the map function are selected for implementation starting with the most significant AI risks. The risks or trustworthiness characteristics that will not – or cannot – be measured are properly documented.

### Measure 1.1.1. Select Appropriate Measurement Approaches.

#### Sub Practices

1. Identify the most significant AI risks identified during the Map function, considering their likelihood, magnitude, and potential impact on stakeholders and society.

2. Assess the feasibility of measuring each identified risk using appropriate measurement approaches, such as quantitative metrics, qualitative assessments, or expert judgment.

3. Prioritize risks for measurement based on their significance, feasibility of measurement, and potential impact on the AI system's trustworthiness.

### Measure 1.1.2. Develop and Implement Measurement Metrics.

#### Sub Practices

1. For each selected risk, develop clear and quantifiable metrics that effectively capture its essence and allow for ongoing measurement.

2. Ensure that the selected metrics are relevant, reliable, and sensitive to changes in the AI system's behavior or context.

3. Validate the measurement metrics through pilot testing and refinement to ensure they accurately reflect the intended risk construct.

### Measure 1.1.3. Establish Measurement Procedures and Tools.

#### Sub Practices

1. Define detailed procedures for collecting, aggregating, and analyzing data related to the selected AI risks.

2. Develop or select appropriate tools and technologies to facilitate data collection, analysis, and reporting.

3. Ensure that the measurement procedures and tools are compatible with the AI system's data infrastructure and performance monitoring capabilities.

### Measure 1.1.4. Integrate Measurement into the AI Development Lifecycle.

#### Sub Practices

1. Incorporate measurement activities into the AI system's development lifecycle, from requirements gathering to deployment and ongoing operations.

2. Schedule regular measurement cycles to track the evolution of AI risks and assess the effectiveness of mitigation strategies.

3. Implement mechanisms for data collection, analysis, and reporting that align with the AI system's operational environment.

### Measure 1.1.5. Document Measurement Approaches and Limitations.

#### Sub Practices

1. Create comprehensive documentation outlining the selected measurement approaches, metrics, procedures, and tools.

2. Clearly identify the AI risks that will not be measured and the reasons for not measuring them.

3. Justify the selection of measurement approaches and address any limitations or limitations of the chosen methodologies.

### Measure 1.1.6. Continuously Evaluate and Improve Measurement Processes.

#### Sub Practices

1. Regularly evaluate the effectiveness of measurement processes and identify areas for improvement.

2. Gather feedback from stakeholders, experts, and data analysts to assess the quality and relevance of measurement data.

