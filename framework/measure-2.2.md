[//]: # (COPYRIGHT)
[//]: # (RiskFrame.ai - AI Risk Management and Resilience Framework)
[//]: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm)
[//]: # (SOFTWARE LICENSE)
[//]: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
    
## Measure 2.2: Evaluations involving human subjects meet applicable requirements (including human subject protection) and are representative of the relevant population.

### Measure 2.2.1. Design and Plan Human-Subject Evaluations.

#### Sub Practices

1. Develop a comprehensive evaluation plan that clearly defines the purpose, scope, methodology, and ethical considerations for human-subject evaluations.

2. Ensure that the evaluation plan aligns with applicable ethical guidelines, regulations, and institutional review board (IRB) requirements.

3. Recruit participants from the relevant population, considering factors such as demographics, cultural backgrounds, and potential biases.

### Measure 2.2.2. Obtain Informed Consent.

#### Sub Practices

1. Obtain informed consent from all participants, providing them with clear and comprehensive information about the evaluation, potential risks, and their rights as research subjects.

2. Use plain language and culturally appropriate methods to ensure that participants understand the informed consent form.

3. Obtain written or verbal consent, depending on the evaluation methodology and the assessment of participants' literacy or comprehension abilities.

### Measure 2.2.3. Protect Participant Privacy.

#### Sub Practices

1. Implement robust data privacy measures to protect the confidentiality, integrity, and availability of participant data.

2. Employ appropriate data encryption, access controls, and anonymization techniques to safeguard sensitive information.

3. Obtain data minimization commitments from all data collectors and processors to minimize the amount of personal data collected and processed.

### Measure 2.2.4. Respect Participant Withdraw and Refusal Rights.

#### Sub Practices

1. Inform participants of their right to withdraw from the evaluation at any time without penalty or negative consequences.

2. Provide clear instructions on how to withdraw from the evaluation, including contact information for the research team and IRB.

3. Respect participant refusals to participate in the evaluation and refrain from pressuring or coercing individuals to participate.

### Measure 2.2.5. Manage Data Collection and Analysis.

#### Sub Practices

1. Collect data from participants in a manner that is ethical, respectful, and consistent with the evaluation plan and informed consent process.

2. Employ data collection tools and procedures that are appropriate for the evaluation's purpose and minimize potential harm to participants.

3. Implement rigorous data analysis methods that are appropriate for the evaluation's methodology and data type.

### Measure 2.2.6. Protect Participant Privacy and Confidentiality During Data Storage and Usage.

#### Sub Practices

1. Store participant data securely in a controlled environment that meets data privacy regulations and organizational security standards.

2. Limit access to participant data to authorized personnel who have a legitimate need to know for the evaluation's purposes.

3. Regularly review and update data security measures to address evolving threats and vulnerabilities.

### Measure 2.2.7. Disclose Study Results and Address Participant Concerns.

#### Sub Practices

1. Disclose the findings of human-subject evaluations to relevant stakeholders, including participants, research communities, and regulatory bodies.

2. Provide participants with an opportunity to review and provide feedback on the evaluation results, addressing any concerns or questions they may have.

3. Utilize evaluation findings to inform the development, improvement, and responsible use of AI systems.

### Measure 2.2.8. Continuously Evaluate and Enhance Human-Subject Evaluation Practices.

#### Sub Practices

1. Regularly review and evaluate the effectiveness of human-subject evaluation practices, identifying areas for improvement and adapting procedures as needed.

2. Gather feedback from participants, researchers, and IRB members to identify potential biases, ethical concerns, or procedural gaps in the evaluation process.

3. Integrate lessons learned from evaluation processes into training programs and guidelines for conducting responsible AI research.

