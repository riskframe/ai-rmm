[//]: # (COPYRIGHT)
[//]: # (RiskFrame.ai - AI Risk Management and Resilience Framework)
[//]: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm)
[//]: # (SOFTWARE LICENSE)
[//]: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
    
## Measure 2.3: AI system performance or assurance criteria are measured qualitatively or quantitatively and demonstrated for conditions similar to deployment setting(s). Measures are documented.

### Measure 2.3.1. Establish Performance or Assurance Criteria.

#### Sub Practices

1. Define clear and measurable performance or assurance criteria that align with the AI system's intended purpose, its trustworthiness characteristics, and the organization's risk tolerance.

2. Consider factors such as accuracy, fairness, robustness, explainability, and security when establishing criteria.

3. Document the rationale behind the selection of criteria, ensuring they are relevant, quantifiable, and achievable.

### Measure 2.3.2. Identify Representative Deployment Settings.

#### Sub Practices

1. Identify and characterize the deployment settings where the AI system will be used, considering factors such as user demographics, data availability, and operating environments.

2. Select representative deployment settings for performance or assurance testing, ensuring they cover a range of potential conditions and usage scenarios.

3. Document the rationale for selecting representative settings, ensuring they are relevant to the AI system's intended use and the organization's risk profile.

### Measure 2.3.3. Develop Measurement Protocols.

#### Sub Practices

1. Develop detailed measurement protocols that outline the procedures for collecting, analyzing, and interpreting data related to the AI system's performance or assurance criteria.

2. Define the metrics to be used for quantitative assessments, ensuring they are relevant, reliable, and sensitive to changes in the AI system's behavior.

3. Establish qualitative assessment methodologies for evaluating trustworthiness characteristics such as fairness, explainability, and robustness.

### Measure 2.3.4. Conduct Performance or Assurance Testing.

#### Sub Practices

1. Conduct performance or assurance testing in representative deployment settings, following the established protocols and utilizing appropriate tools and technologies.

2. Collect data from testing runs, including metrics and qualitative observations, to assess the AI system's performance or assurance against the established criteria.

3. Document the testing results, including any discrepancies between observed performance and expected outcomes.

### Measure 2.3.5. Analyze and Interpret Test Results.

#### Sub Practices

1. Analyze the collected data to identify patterns, trends, and potential areas for improvement in the AI system's performance or assurance.

2. Interpret the test results in the context of the AI system's intended use, deployment settings, and organizational risk profile.

3. Draw conclusions about the AI system's compliance with performance or assurance criteria and identify any potential risks or limitations.

### Measure 2.3.6. Document Performance or Assurance Demonstration.

#### Sub Practices

1. Create comprehensive documentation that summarizes the performance or assurance criteria, measurement protocols, testing results, and analysis findings.

2. Document the demonstration of performance or assurance in representative deployment settings, including screenshots, data visualizations, and narrative explanations.

3. Share the documentation with relevant stakeholders, including developers, testers, risk managers, and decision-makers.

### Measure 2.3.7. Continuously Evaluate and Adapt Performance or Assurance Measures.

#### Sub Practices

1. Regularly evaluate the effectiveness of performance or assurance measures, identifying areas for improvement and adapting criteria as the AI system evolves and new risks emerge.

2. Gather feedback from stakeholders and incorporate new insights into the measurement protocols and testing procedures.

3. Maintain a living document that reflects the dynamic nature of the AI system's performance and assurance, ensuring it remains relevant and aligned with organizational objectives.

